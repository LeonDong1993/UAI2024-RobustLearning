{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567d855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os, pdb, warnings\n",
    "sys.path.insert(0, './core/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=120, precision=4)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b57a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from models.ours.Gaussians import MultivariateGaussain, MixMG\n",
    "\n",
    "class MixMGLearner:\n",
    "    def __init__(self, n_components = 2, reg_covar = 1e-6, tol = 1e-3, max_iter = 100):\n",
    "        self.n_components = n_components\n",
    "        self.reg_covar = reg_covar\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def fit(self, train, weight = None):\n",
    "        N, D = train.shape\n",
    "        if weight is None:\n",
    "            weight = np.ones( shape = (N, ) )\n",
    "        \n",
    "        # init the component weights\n",
    "        self.w = np.ones( shape = (self.n_components, ) ) / self.n_components\n",
    "        \n",
    "        # use kmeans to find the initial center \n",
    "        clf = KMeans(n_clusters = self.n_components, init='k-means++', n_init = 10).fit(train)\n",
    "        \n",
    "        sub_models = []\n",
    "        for i in range(self.n_components):\n",
    "            mg = MultivariateGaussain()\n",
    "            mg.mu = clf.cluster_centers_[i,:]\n",
    "            mg.S = np.identity(D)\n",
    "            sub_models.append(mg)\n",
    "        \n",
    "        self.mgs = sub_models\n",
    "        \n",
    "        # define the Q, Q[i,j] the probility that sample i falls into j component\n",
    "        self.Q = np.ones(shape = (N, self.n_components)) / self.n_components\n",
    "        \n",
    "        # define the V, V[i,j] is the density of sample i under j component\n",
    "        self.V = np.ones(shape = (N, self.n_components)) / self.n_components\n",
    "        \n",
    "        # need to update convergence criteria\n",
    "        n_iter = 0\n",
    "        converged = False\n",
    "        while not converged:\n",
    "            n_iter += 1\n",
    "            \n",
    "            # compute V for the e step\n",
    "            for i in range(self.n_components):\n",
    "                masses = self.mgs[i].mass(train, logmode = 1)\n",
    "                # originally, it is power\n",
    "                masses = masses * weight.flatten()\n",
    "                self.V[:,i] = masses\n",
    "            \n",
    "            self._estep()\n",
    "            self._mstep(train, weight)\n",
    "            if n_iter >= self.max_iter:\n",
    "                break\n",
    "        return self\n",
    "    \n",
    "    def _estep(self):\n",
    "        w = self.w.reshape(1, -1)\n",
    "        self.Q = (self.V + np.log(w))\n",
    "        # basically numertical stable softmax here\n",
    "        self.Q -= np.max(self.Q, axis = 1, keepdims = True)\n",
    "        self.Q = np.exp(self.Q)\n",
    "        row_sum = self.Q.sum(axis = 1, keepdims = True)\n",
    "        self.Q = self.Q / row_sum\n",
    "        \n",
    "    def _mstep(self, data, weight):\n",
    "        # update w\n",
    "        self.w = self.Q.mean(axis=0)\n",
    "        \n",
    "        # update mu \n",
    "        weight = weight.reshape(-1, 1)\n",
    "        wQ = weight * self.Q\n",
    "        \n",
    "        Qcol_sum = wQ.sum(axis = 0)\n",
    "        for i in range(self.n_components):\n",
    "            self.mgs[i].mu = np.sum( wQ[:, i:i+1] * data, axis = 0) / Qcol_sum[i]\n",
    "        \n",
    "        # update cov matrix \n",
    "        for i in range(self.n_components):\n",
    "            mu = self.mgs[i].mu.reshape(1, -1)\n",
    "            mat = data - mu\n",
    "            mat2 = mat.copy()\n",
    "            mat2 = wQ[:, i:i+1] * mat2 / (self.w[i] * data.shape[0])\n",
    "            S = mat.T @ mat2\n",
    "            S += np.identity(mu.size) * self.reg_covar\n",
    "            self.mgs[i].S = S\n",
    "        \n",
    "    def get_model(self):\n",
    "        model = MixMG()\n",
    "        model.W = self.w\n",
    "        model.models = self.mgs\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b62a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-36.7454 -34.842  -32.8224 -31.1787 -29.9868]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils.extmath import row_norms\n",
    "from sklearn.datasets._samples_generator import make_blobs\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "X, _ = make_blobs(n_samples=4000, centers=5, cluster_std=2.0, n_features = 15)\n",
    "md1 = MixMG().fit(X, n_comps = 5)\n",
    "print(np.percentile(md1.mass(X, logmode = 1), [10,25,50,75,90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7518024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-36.7454 -34.842  -32.8224 -31.1787 -29.9868]\n"
     ]
    }
   ],
   "source": [
    "lm = MixMGLearner(n_components = 5).fit(X)\n",
    "md2 = lm.get_model()\n",
    "print(np.percentile(md2.mass(X, logmode = 1), [10,25,50,75,90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bcd1d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.7519  0.0906  2.7573 -3.9051 -6.4964  8.8368 -3.9939  9.1159  8.6867 -2.9059 -8.6172 -3.16    8.9408  0.3486\n",
      "  6.2774]\n",
      "[-1.4998  8.1111  1.6714  8.7511 -0.6194 -4.39   -4.75   -2.1825  3.6725 -2.6952  9.1607  1.2819  5.6106  0.6879\n",
      "  8.5418]\n",
      "[-1.4998  8.1111  1.6714  8.7511 -0.6194 -4.39   -4.75   -2.1825  3.6725 -2.6952  9.1607  1.2819  5.6106  0.6879\n",
      "  8.5418]\n",
      "[-5.7519  0.0906  2.7573 -3.9051 -6.4964  8.8368 -3.9939  9.1159  8.6867 -2.9059 -8.6172 -3.16    8.9408  0.3486\n",
      "  6.2774]\n",
      "[-3.3451 -5.527   9.924   2.5989  0.5635  6.4402  0.5545  5.1935 -2.4956  7.7788  9.8388 -1.5097 -2.0615 -7.1917\n",
      "  0.851 ]\n",
      "[-3.3451 -5.527   9.924   2.5989  0.5635  6.4402  0.5545  5.1935 -2.4956  7.7788  9.8388 -1.5097 -2.0615 -7.1917\n",
      "  0.851 ]\n",
      "[ 6.4255 -4.8286 -0.4609 -5.0437 -5.5984  7.2656 -2.3088 -7.5799  8.8677  3.9372 -9.459   5.3013 -1.5698  4.9344\n",
      "  7.4433]\n",
      "[ 6.4255 -4.8286 -0.4609 -5.0437 -5.5984  7.2656 -2.3088 -7.5799  8.8677  3.9372 -9.459   5.3013 -1.5698  4.9344\n",
      "  7.4433]\n",
      "[ 1.3517  3.3626  1.7261  8.9995 -4.3875 -3.1573  7.4497 -2.4311  6.0849  3.9499 -2.3103  7.5155  6.3163 -1.3791\n",
      "  1.7027]\n",
      "[ 1.3517  3.3626  1.7261  8.9995 -4.3875 -3.1573  7.4497 -2.4311  6.0849  3.9499 -2.3103  7.5155  6.3163 -1.3791\n",
      "  1.7027]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(md1.models[i].mu)\n",
    "    print(md2.models[i].mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afca090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all digits datasets\n",
    "import loader\n",
    "from functools import partial\n",
    "\n",
    "mnist_dir = './data/digits/mnist'\n",
    "ch74_dir = './data/digits/chars74k'\n",
    "dida_dir = './data/digits/dida'\n",
    "NUM_PER_CLASS = 30\n",
    "DOWN_SAMPLE = True\n",
    "N_MNIST = 25000\n",
    "\n",
    "def visualize_imgs(img_array, rows = 3, cols = 8, selected = None):\n",
    "    if DOWN_SAMPLE:\n",
    "        process = lambda x:x.reshape(14,14)\n",
    "    else:\n",
    "        process = lambda x:x.reshape(28,28)\n",
    "    if selected is None:\n",
    "        assert(img_array.shape[0] >= rows * cols)\n",
    "        selected = np.random.choice(img_array.shape[0], rows * cols, replace = False)\n",
    "    else:\n",
    "        assert(selected.size >= rows * cols)\n",
    "        \n",
    "    k = 1\n",
    "    fid = plt.figure()\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            plt.subplot(rows, cols, k)\n",
    "            plt.imshow(process(img_array[selected[k-1]]), cmap='gray' )\n",
    "            k += 1\n",
    "            plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "mnist_train, mnist_test = loader.read_mnist(mnist_dir, down_sample = DOWN_SAMPLE, with_label = False)\n",
    "ch74 = loader.read_chars74k(ch74_dir, NUM_PER_CLASS)\n",
    "ch74 = np.array(list(map(partial(loader.transform_to_mnist, down_sample = DOWN_SAMPLE, normalize = False) ,ch74)))\n",
    "dida = loader.read_dida(dida_dir, NUM_PER_CLASS)\n",
    "dida = np.array(list(map(partial(loader.transform_to_mnist, down_sample = DOWN_SAMPLE, normalize = True) ,dida)))\n",
    "\n",
    "# sub-sample mnist for train and augment with reversed color \n",
    "np.random.seed(3)\n",
    "sub_train = mnist_train[np.random.choice(np.arange(mnist_train.shape[0]), size = N_MNIST, replace = False)]\n",
    "mnist_train = np.vstack([sub_train, 1-sub_train])\n",
    "np.random.shuffle(mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "997b963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.34634160995483\n",
      "[456.0693 487.9154 519.8477 614.0098 652.6449]\n",
      "100.84434461593628\n",
      "[460.7315 495.122  530.2283 616.4325 642.0958]\n"
     ]
    }
   ],
   "source": [
    "# do some test on mnist dataset\n",
    "import time\n",
    "data = mnist_train[0:5000, :]\n",
    "st = time.time()\n",
    "md1 = MixMG().fit(data, n_comps = 10)\n",
    "ed = time.time()\n",
    "print(ed - st)\n",
    "print(np.percentile(md1.mass(data, logmode = 1), [10,25,50,75,90]))\n",
    "st = time.time()\n",
    "lm = MixMGLearner(n_components = 10).fit(data)\n",
    "md2 = lm.get_model()\n",
    "ed = time.time()\n",
    "print(ed - st)\n",
    "print(np.percentile(md2.mass(data, logmode = 1), [10,25,50,75,90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93fdd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.47815942764282\n",
      "[443.6595 489.8257 531.9295 610.68   652.9033]\n"
     ]
    }
   ],
   "source": [
    "# test if we have some weight on data\n",
    "weight = np.random.rand(5000)\n",
    "weight = weight / weight.sum() * 5000\n",
    "\n",
    "st = time.time()\n",
    "lm = MixMGLearner(n_components = 10).fit(data, weight)\n",
    "md3 = lm.get_model()\n",
    "ed = time.time()\n",
    "print(ed - st)\n",
    "print(np.percentile(md3.mass(data, logmode = 1), [10,25,50,75,90]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4768b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540.7888940204662\n",
      "545.0785485788617\n",
      "529.2828656869956\n",
      "541.0112098229312\n",
      "545.031702986258\n",
      "547.8828863405189\n",
      "[456.0693 487.9154 519.8477 614.0098 652.6449]\n",
      "[460.7315 495.122  530.2283 616.4325 642.0958]\n",
      "[443.6595 489.8257 531.9295 610.68   652.9033]\n",
      "[106.0825 265.5519 534.4411 795.7023 973.9185]\n",
      "[105.0261 267.9611 539.3853 804.9909 977.7571]\n",
      "[ 95.879  258.633  541.4898 820.5335 995.3232]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(md1.mass(data, logmode = 1) ))\n",
    "print(np.mean(md2.mass(data, logmode = 1) ))\n",
    "print(np.mean(md3.mass(data, logmode = 1) ))\n",
    "\n",
    "\n",
    "print(np.mean(md1.mass(data, logmode = 1) * weight))\n",
    "print(np.mean(md2.mass(data, logmode = 1) * weight))\n",
    "print(np.mean(md3.mass(data, logmode = 1) * weight))\n",
    "\n",
    "print(np.percentile(md1.mass(data, logmode = 1), [10,25,50,75,90]))\n",
    "print(np.percentile(md2.mass(data, logmode = 1), [10,25,50,75,90]))\n",
    "print(np.percentile(md3.mass(data, logmode = 1), [10,25,50,75,90]))\n",
    "\n",
    "print(np.percentile(md1.mass(data, logmode = 1) * weight, [10,25,50,75,90]))\n",
    "print(np.percentile(md2.mass(data, logmode = 1) * weight, [10,25,50,75,90]))\n",
    "print(np.percentile(md3.mass(data, logmode = 1) * weight, [10,25,50,75,90]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55539458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa88a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed4d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a67744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
